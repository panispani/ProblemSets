{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/panayiotis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/panayiotis/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If not already downloaded, run this once to download wordnet and stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_DATA_PATH = os.path.join('data', 'cases_metadata.csv')\n",
    "DATA_DIR = os.path.join('data', 'cases')\n",
    "NUM_CASES = 1000 # Perform analysis on 1000 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4562\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "cases = pd.read_csv(META_DATA_PATH)\n",
    "\n",
    "# Drop all cases with NaNs\n",
    "cases.dropna(subset=['x_republican'],inplace=True)\n",
    "cases.dropna(subset=['log_cites'],inplace=True)\n",
    "# Use subset of cases\n",
    "# cases = cases.sample(NUM_CASES)\n",
    "# Display how many NaNs there are per column\n",
    "# print(cases.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      caseid  case_reversed  judge_id    year  x_republican  log_cites  \\\n",
      "5099  X2AK86              1    1316.0  2001.0           0.0   2.397895   \n",
      "5096  X50MTC              1     739.0  2001.0           1.0   2.079442   \n",
      "1977  X3CTHD              0     850.0  1951.0           1.0   0.693147   \n",
      "1215  XABCL8              0     232.0  1979.0           0.0   2.708050   \n",
      "1718  X3ABOL              0    2162.0  1996.0           1.0   3.135494   \n",
      "\n",
      "                                                   text  \n",
      "5099   OPINION BOYCE F. MARTIN, Jr.\\n, Chief Judge.\\...  \n",
      "5096   JOHN R. GIBSON , Circuit Judge.\\nThe issue be...  \n",
      "1977   L. HAND , Circuit Judge.\\nThis is an appeal f...  \n",
      "1215   BAILEY BROWN , Chief District Judge.\\nThese t...  \n",
      "1718   OPINION WALLACE , Circuit Judge: The City of ...  \n"
     ]
    }
   ],
   "source": [
    "# Load texts and add to dataframe\n",
    "\n",
    "texts = []\n",
    "for caseid in cases.caseid:\n",
    "    file = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(caseid + '.txt')]\n",
    "    # Make sure you found the right file and is unique\n",
    "    assert len(file) == 1\n",
    "    text = open(file[0]).read()\n",
    "    texts.append(text)\n",
    "    \n",
    "cases['text'] = texts\n",
    "print(cases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      caseid  case_reversed  judge_id    year  x_republican  log_cites  \\\n",
      "5099  X2AK86              1    1316.0  2001.0           0.0   2.397895   \n",
      "5096  X50MTC              1     739.0  2001.0           1.0   2.079442   \n",
      "1977  X3CTHD              0     850.0  1951.0           1.0   0.693147   \n",
      "1215  XABCL8              0     232.0  1979.0           0.0   2.708050   \n",
      "1718  X3ABOL              0    2162.0  1996.0           1.0   3.135494   \n",
      "\n",
      "                                                   text  \\\n",
      "5099   OPINION BOYCE F. MARTIN, Jr.\\n, Chief Judge.\\...   \n",
      "5096   JOHN R. GIBSON , Circuit Judge.\\nThe issue be...   \n",
      "1977   L. HAND , Circuit Judge.\\nThis is an appeal f...   \n",
      "1215   BAILEY BROWN , Chief District Judge.\\nThese t...   \n",
      "1718   OPINION WALLACE , Circuit Judge: The City of ...   \n",
      "\n",
      "                                         processed_text  \n",
      "5099  opinion boyce f martin jr chief judge december...  \n",
      "5096  john r gibson circuit judge issue u appeal whe...  \n",
      "1977  l hand circuit judge appeal judgment summarily...  \n",
      "1215  bailey brown chief district judge two appeal c...  \n",
      "1718  opinion wallace circuit judge city monterey ci...  \n"
     ]
    }
   ],
   "source": [
    "# Data normalization and pre-processing\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "def normalize(text):\n",
    "    # Lower case\n",
    "    text = text.lower()\n",
    "    # Remove whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    # Remove weird non-printable characters\n",
    "    text = ''.join([c for c in text if c in string.printable])\n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('','',punctuation) \n",
    "    text = text.translate(translator)\n",
    "    # Remove stopwords\n",
    "    stoplist = stopwords.words('english')\n",
    "    text = ' '.join(word for word in text.split() if word not in stoplist)\n",
    "    # lematize, need to pass words individually\n",
    "    text = ' '.join(nltk.WordNetLemmatizer().lemmatize(word) for word in text.split())\n",
    "    all_sentences.append(text.split())\n",
    "    return text\n",
    "                   \n",
    "# Apply normalization to the text of each case\n",
    "cases['processed_text'] = cases['text'].apply(normalize)\n",
    "print(cases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec small window=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller window we expect similar words to have very similar vectors, even if they don't to the same context (this is not well captured by a small window size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(sentences, window):\n",
    "    w2v = Word2Vec(sentences,\n",
    "                    workers=10,\n",
    "                    size=300,\n",
    "                    min_count=20,\n",
    "                    window=window,\n",
    "                    sample=1e-3)\n",
    "    w2v.init_sims(replace=True)\n",
    "    return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('situation', 0.6267842650413513),\n",
       " ('proceeding', 0.5038460493087769),\n",
       " ('litigation', 0.500220775604248),\n",
       " ('controversy', 0.46203505992889404),\n",
       " ('distinguishable', 0.4511649012565613),\n",
       " ('event', 0.4451952576637268),\n",
       " ('appeal', 0.43351566791534424),\n",
       " ('instance', 0.42852669954299927),\n",
       " ('briefly', 0.41980624198913574),\n",
       " ('moitie', 0.4166962802410126)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_small = train_word2vec(all_sentences, 2)\n",
    "w2v_small.init_sims(replace=True)\n",
    "w2v_small.save('w2v-small.pkl')\n",
    "w2v_small.wv.most_similar('case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec big window=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigger window we expect words that belong to the same context to have similar words, similar topics would have similar vectors, we can inspect this by looking at the closest vectors to a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('distinguishable', 0.6295070648193359),\n",
       " ('instant', 0.6217772960662842),\n",
       " ('situation', 0.6216025352478027),\n",
       " ('decided', 0.5876038074493408),\n",
       " ('controlling', 0.5637916922569275),\n",
       " ('moitie', 0.5580907464027405),\n",
       " ('re', 0.5386110544204712),\n",
       " ('present', 0.5328385829925537),\n",
       " ('involved', 0.5301691293716431),\n",
       " ('judicata', 0.5274114608764648)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_big = train_word2vec(all_sentences, 16)\n",
    "w2v_big.init_sims(replace=True)\n",
    "w2v_big.save('w2v-big.pkl')\n",
    "w2v_big.wv.most_similar('case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking a sample of 100 words and visualizing them in two dimensions, to demonstrate the difference between the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
